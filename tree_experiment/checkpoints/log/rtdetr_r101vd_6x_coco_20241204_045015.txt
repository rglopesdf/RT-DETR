Not init distributed mode.
Start training
Load PResNet101 state_dict
Initial lr:  [1e-06, 0.0001]
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
number of params: 76365411
Epoch: [0]  [ 0/33]  eta: 0:01:23  lr: 0.000001  loss: 35.3680 (35.3680)  loss_vfl: 0.3626 (0.3626)  loss_bbox: 0.7618 (0.7618)  loss_giou: 1.7230 (1.7230)  loss_vfl_aux_0: 0.3424 (0.3424)  loss_bbox_aux_0: 0.7730 (0.7730)  loss_giou_aux_0: 1.7412 (1.7412)  loss_vfl_aux_1: 0.3516 (0.3516)  loss_bbox_aux_1: 0.7255 (0.7255)  loss_giou_aux_1: 1.7230 (1.7230)  loss_vfl_aux_2: 0.3705 (0.3705)  loss_bbox_aux_2: 0.7335 (0.7335)  loss_giou_aux_2: 1.7388 (1.7388)  loss_vfl_aux_3: 0.3514 (0.3514)  loss_bbox_aux_3: 0.7201 (0.7201)  loss_giou_aux_3: 1.7292 (1.7292)  loss_vfl_aux_4: 0.3737 (0.3737)  loss_bbox_aux_4: 0.7250 (0.7250)  loss_giou_aux_4: 1.7188 (1.7188)  loss_vfl_aux_5: 0.2805 (0.2805)  loss_bbox_aux_5: 0.7129 (0.7129)  loss_giou_aux_5: 1.7193 (1.7193)  loss_vfl_dn_0: 0.9117 (0.9117)  loss_bbox_dn_0: 0.4210 (0.4210)  loss_giou_dn_0: 1.3682 (1.3682)  loss_vfl_dn_1: 0.7852 (0.7852)  loss_bbox_dn_1: 0.4210 (0.4210)  loss_giou_dn_1: 1.3682 (1.3682)  loss_vfl_dn_2: 0.8152 (0.8152)  loss_bbox_dn_2: 0.4210 (0.4210)  loss_giou_dn_2: 1.3682 (1.3682)  loss_vfl_dn_3: 0.7415 (0.7415)  loss_bbox_dn_3: 0.4210 (0.4210)  loss_giou_dn_3: 1.3682 (1.3682)  loss_vfl_dn_4: 0.8428 (0.8428)  loss_bbox_dn_4: 0.4210 (0.4210)  loss_giou_dn_4: 1.3682 (1.3682)  loss_vfl_dn_5: 0.8585 (0.8585)  loss_bbox_dn_5: 0.4210 (0.4210)  loss_giou_dn_5: 1.3682 (1.3682)  time: 2.5303  data: 0.5618  max mem: 4114
Epoch: [0]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 29.0339 (30.4558)  loss_vfl: 0.4176 (0.4259)  loss_bbox: 0.5382 (0.6262)  loss_giou: 1.4446 (1.4751)  loss_vfl_aux_0: 0.3537 (0.4031)  loss_bbox_aux_0: 0.5517 (0.6406)  loss_giou_aux_0: 1.4459 (1.4859)  loss_vfl_aux_1: 0.3659 (0.3942)  loss_bbox_aux_1: 0.5435 (0.6307)  loss_giou_aux_1: 1.4447 (1.4795)  loss_vfl_aux_2: 0.4090 (0.4240)  loss_bbox_aux_2: 0.5425 (0.6269)  loss_giou_aux_2: 1.4454 (1.4763)  loss_vfl_aux_3: 0.4109 (0.4194)  loss_bbox_aux_3: 0.5385 (0.6262)  loss_giou_aux_3: 1.4445 (1.4758)  loss_vfl_aux_4: 0.4185 (0.4211)  loss_bbox_aux_4: 0.5343 (0.6251)  loss_giou_aux_4: 1.4447 (1.4742)  loss_vfl_aux_5: 0.3257 (0.3444)  loss_bbox_aux_5: 0.5627 (0.6426)  loss_giou_aux_5: 1.4473 (1.4872)  loss_vfl_dn_0: 0.3163 (0.3808)  loss_bbox_dn_0: 0.3955 (0.4056)  loss_giou_dn_0: 1.3639 (1.3752)  loss_vfl_dn_1: 0.3173 (0.3479)  loss_bbox_dn_1: 0.3972 (0.4067)  loss_giou_dn_1: 1.3612 (1.3748)  loss_vfl_dn_2: 0.3165 (0.3538)  loss_bbox_dn_2: 0.3995 (0.4083)  loss_giou_dn_2: 1.3584 (1.3753)  loss_vfl_dn_3: 0.3265 (0.3448)  loss_bbox_dn_3: 0.4014 (0.4096)  loss_giou_dn_3: 1.3569 (1.3765)  loss_vfl_dn_4: 0.3291 (0.3546)  loss_bbox_dn_4: 0.4028 (0.4108)  loss_giou_dn_4: 1.3646 (1.3791)  loss_vfl_dn_5: 0.3305 (0.3541)  loss_bbox_dn_5: 0.4042 (0.4120)  loss_giou_dn_5: 1.3650 (1.3817)  time: 0.3535  data: 0.0150  max mem: 7785
Epoch: [0] Total time: 0:00:14 (0.4530 s / it)
Averaged stats: lr: 0.000001  loss: 29.0339 (30.4558)  loss_vfl: 0.4176 (0.4259)  loss_bbox: 0.5382 (0.6262)  loss_giou: 1.4446 (1.4751)  loss_vfl_aux_0: 0.3537 (0.4031)  loss_bbox_aux_0: 0.5517 (0.6406)  loss_giou_aux_0: 1.4459 (1.4859)  loss_vfl_aux_1: 0.3659 (0.3942)  loss_bbox_aux_1: 0.5435 (0.6307)  loss_giou_aux_1: 1.4447 (1.4795)  loss_vfl_aux_2: 0.4090 (0.4240)  loss_bbox_aux_2: 0.5425 (0.6269)  loss_giou_aux_2: 1.4454 (1.4763)  loss_vfl_aux_3: 0.4109 (0.4194)  loss_bbox_aux_3: 0.5385 (0.6262)  loss_giou_aux_3: 1.4445 (1.4758)  loss_vfl_aux_4: 0.4185 (0.4211)  loss_bbox_aux_4: 0.5343 (0.6251)  loss_giou_aux_4: 1.4447 (1.4742)  loss_vfl_aux_5: 0.3257 (0.3444)  loss_bbox_aux_5: 0.5627 (0.6426)  loss_giou_aux_5: 1.4473 (1.4872)  loss_vfl_dn_0: 0.3163 (0.3808)  loss_bbox_dn_0: 0.3955 (0.4056)  loss_giou_dn_0: 1.3639 (1.3752)  loss_vfl_dn_1: 0.3173 (0.3479)  loss_bbox_dn_1: 0.3972 (0.4067)  loss_giou_dn_1: 1.3612 (1.3748)  loss_vfl_dn_2: 0.3165 (0.3538)  loss_bbox_dn_2: 0.3995 (0.4083)  loss_giou_dn_2: 1.3584 (1.3753)  loss_vfl_dn_3: 0.3265 (0.3448)  loss_bbox_dn_3: 0.4014 (0.4096)  loss_giou_dn_3: 1.3569 (1.3765)  loss_vfl_dn_4: 0.3291 (0.3546)  loss_bbox_dn_4: 0.4028 (0.4108)  loss_giou_dn_4: 1.3646 (1.3791)  loss_vfl_dn_5: 0.3305 (0.3541)  loss_bbox_dn_5: 0.4042 (0.4120)  loss_giou_dn_5: 1.3650 (1.3817)
Test:  [0/6]  eta: 0:00:06    time: 1.1228  data: 0.6852  max mem: 7785
Test:  [5/6]  eta: 0:00:00    time: 0.4528  data: 0.1265  max mem: 7785
Test: Total time: 0:00:04 (0.7098 s / it)
Averaged stats: 
Accumulating evaluation results...
DONE (t=0.05s).
IoU metric: bbox
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.001
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.004
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.003
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.018
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.014
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.107
best_stat:  {'epoch': 0, 'coco_eval_bbox': 0.0002586547492052941}
Epoch: [1]  [ 0/33]  eta: 0:00:35  lr: 0.000001  loss: 28.3734 (28.3734)  loss_vfl: 0.4671 (0.4671)  loss_bbox: 0.5506 (0.5506)  loss_giou: 1.2168 (1.2168)  loss_vfl_aux_0: 0.4373 (0.4373)  loss_bbox_aux_0: 0.5766 (0.5766)  loss_giou_aux_0: 1.2429 (1.2429)  loss_vfl_aux_1: 0.4287 (0.4287)  loss_bbox_aux_1: 0.5709 (0.5709)  loss_giou_aux_1: 1.2371 (1.2371)  loss_vfl_aux_2: 0.4488 (0.4488)  loss_bbox_aux_2: 0.5582 (0.5582)  loss_giou_aux_2: 1.2287 (1.2287)  loss_vfl_aux_3: 0.4620 (0.4620)  loss_bbox_aux_3: 0.5570 (0.5570)  loss_giou_aux_3: 1.2220 (1.2220)  loss_vfl_aux_4: 0.4543 (0.4543)  loss_bbox_aux_4: 0.5575 (0.5575)  loss_giou_aux_4: 1.2201 (1.2201)  loss_vfl_aux_5: 0.3700 (0.3700)  loss_bbox_aux_5: 0.6154 (0.6154)  loss_giou_aux_5: 1.2806 (1.2806)  loss_vfl_dn_0: 0.3207 (0.3207)  loss_bbox_dn_0: 0.4402 (0.4402)  loss_giou_dn_0: 1.3385 (1.3385)  loss_vfl_dn_1: 0.3145 (0.3145)  loss_bbox_dn_1: 0.4427 (0.4427)  loss_giou_dn_1: 1.3294 (1.3294)  loss_vfl_dn_2: 0.3294 (0.3294)  loss_bbox_dn_2: 0.4459 (0.4459)  loss_giou_dn_2: 1.3224 (1.3224)  loss_vfl_dn_3: 0.3460 (0.3460)  loss_bbox_dn_3: 0.4484 (0.4484)  loss_giou_dn_3: 1.3180 (1.3180)  loss_vfl_dn_4: 0.3767 (0.3767)  loss_bbox_dn_4: 0.4503 (0.4503)  loss_giou_dn_4: 1.3149 (1.3149)  loss_vfl_dn_5: 0.3664 (0.3664)  loss_bbox_dn_5: 0.4524 (0.4524)  loss_giou_dn_5: 1.3139 (1.3139)  time: 1.0619  data: 0.6725  max mem: 7785
Epoch: [1]  [32/33]  eta: 0:00:00  lr: 0.000001  loss: 27.9799 (29.2251)  loss_vfl: 0.6021 (0.5487)  loss_bbox: 0.4596 (0.5717)  loss_giou: 1.1484 (1.2688)  loss_vfl_aux_0: 0.4393 (0.4181)  loss_bbox_aux_0: 0.5036 (0.6295)  loss_giou_aux_0: 1.2892 (1.3427)  loss_vfl_aux_1: 0.4836 (0.4442)  loss_bbox_aux_1: 0.5002 (0.6126)  loss_giou_aux_1: 1.2391 (1.3222)  loss_vfl_aux_2: 0.5099 (0.4664)  loss_bbox_aux_2: 0.4890 (0.5969)  loss_giou_aux_2: 1.2121 (1.3039)  loss_vfl_aux_3: 0.5462 (0.5031)  loss_bbox_aux_3: 0.4767 (0.5855)  loss_giou_aux_3: 1.1799 (1.2887)  loss_vfl_aux_4: 0.5817 (0.5367)  loss_bbox_aux_4: 0.4640 (0.5770)  loss_giou_aux_4: 1.1617 (1.2758)  loss_vfl_aux_5: 0.3714 (0.3601)  loss_bbox_aux_5: 0.5527 (0.6729)  loss_giou_aux_5: 1.3234 (1.3943)  loss_vfl_dn_0: 0.3267 (0.3216)  loss_bbox_dn_0: 0.4002 (0.4364)  loss_giou_dn_0: 1.3332 (1.3350)  loss_vfl_dn_1: 0.3270 (0.3258)  loss_bbox_dn_1: 0.3972 (0.4350)  loss_giou_dn_1: 1.2932 (1.3187)  loss_vfl_dn_2: 0.3348 (0.3313)  loss_bbox_dn_2: 0.3941 (0.4359)  loss_giou_dn_2: 1.2780 (1.3108)  loss_vfl_dn_3: 0.3372 (0.3352)  loss_bbox_dn_3: 0.3949 (0.4370)  loss_giou_dn_3: 1.2830 (1.3089)  loss_vfl_dn_4: 0.3346 (0.3371)  loss_bbox_dn_4: 0.3962 (0.4384)  loss_giou_dn_4: 1.2908 (1.3085)  loss_vfl_dn_5: 0.3462 (0.3414)  loss_bbox_dn_5: 0.3956 (0.4389)  loss_giou_dn_5: 1.2957 (1.3094)  time: 0.3474  data: 0.0146  max mem: 7785
Epoch: [1] Total time: 0:00:12 (0.3682 s / it)
Averaged stats: lr: 0.000001  loss: 27.9799 (29.2251)  loss_vfl: 0.6021 (0.5487)  loss_bbox: 0.4596 (0.5717)  loss_giou: 1.1484 (1.2688)  loss_vfl_aux_0: 0.4393 (0.4181)  loss_bbox_aux_0: 0.5036 (0.6295)  loss_giou_aux_0: 1.2892 (1.3427)  loss_vfl_aux_1: 0.4836 (0.4442)  loss_bbox_aux_1: 0.5002 (0.6126)  loss_giou_aux_1: 1.2391 (1.3222)  loss_vfl_aux_2: 0.5099 (0.4664)  loss_bbox_aux_2: 0.4890 (0.5969)  loss_giou_aux_2: 1.2121 (1.3039)  loss_vfl_aux_3: 0.5462 (0.5031)  loss_bbox_aux_3: 0.4767 (0.5855)  loss_giou_aux_3: 1.1799 (1.2887)  loss_vfl_aux_4: 0.5817 (0.5367)  loss_bbox_aux_4: 0.4640 (0.5770)  loss_giou_aux_4: 1.1617 (1.2758)  loss_vfl_aux_5: 0.3714 (0.3601)  loss_bbox_aux_5: 0.5527 (0.6729)  loss_giou_aux_5: 1.3234 (1.3943)  loss_vfl_dn_0: 0.3267 (0.3216)  loss_bbox_dn_0: 0.4002 (0.4364)  loss_giou_dn_0: 1.3332 (1.3350)  loss_vfl_dn_1: 0.3270 (0.3258)  loss_bbox_dn_1: 0.3972 (0.4350)  loss_giou_dn_1: 1.2932 (1.3187)  loss_vfl_dn_2: 0.3348 (0.3313)  loss_bbox_dn_2: 0.3941 (0.4359)  loss_giou_dn_2: 1.2780 (1.3108)  loss_vfl_dn_3: 0.3372 (0.3352)  loss_bbox_dn_3: 0.3949 (0.4370)  loss_giou_dn_3: 1.2830 (1.3089)  loss_vfl_dn_4: 0.3346 (0.3371)  loss_bbox_dn_4: 0.3962 (0.4384)  loss_giou_dn_4: 1.2908 (1.3085)  loss_vfl_dn_5: 0.3462 (0.3414)  loss_bbox_dn_5: 0.3956 (0.4389)  loss_giou_dn_5: 1.2957 (1.3094)
